{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font><b>第九章 EM算法及其推广 </b></font> P195-P212 ……18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、EM算法是一种迭代算法，用于含有隐变量（hidden variable) 的概率模型参数的极大似然估计，或极大后验概率估计。\n",
    "\n",
    "2、**EM算法每次迭代由两步组成： E步，求期望(expectation); M步，求极大(Maximization)**\n",
    "\n",
    "3、这一算法称为期望极大算法（Expectation Maximization algorithm）,简称EM算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **一、EM算法的引入** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概率模型有时即含有观测变量（observable variable)，又含有隐变量或潜在变量（latent variable); 如果概率模型的变量都是观测变量，可以直接用极大似然估计或贝叶斯估计法估计模型参数。 如果含有隐变量，就不能简单地用这些方法。EM算法，就是含有隐变量的概率模型参数的极大似然估计法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：观测变量数量$Y$，隐变量数据$Z$, 联合分布 $P(Y,Z|\\theta)$, 条件分布 $P(Z|Y,\\theta)$\n",
    "\n",
    "输出：模型参数 $\\theta$\n",
    "\n",
    " （1）选择参数的初值 $\\theta^{(0)}$, 开始迭代\n",
    " \n",
    " （2） E步： 记 $\\theta^{(i)}$ 为第 $i$ 次迭代参数 $\\theta$ 的估计值，在第 $i+1$次迭代的 E 步，计算\n",
    " #### $$Q(\\theta, \\theta^{(i)}) = E_Z[logP(Y,Z|\\theta)|Y,\\theta^{(i)}] = \\sum_Z log(P(Y,Z|\\theta)P(Z|Y,\\theta^{(i)})$$\n",
    " 这里， $P(Z|Y,\\theta^{(i)})$ 是在给定观测数据 $Y$ 和当前的参数估计 $\\theta^{(i)}$ 下隐变量数据 $Z$ 的条件概率分布：\n",
    " \n",
    " （3） M步：求使 $Q(\\theta,\\theta^{(i)})$ 极大化的 $\\theta$, 确定第 $i+1$ 次迭代的参数估计值 $\\theta^{(i+1)}$ \n",
    " #### $$\\theta^{(i+1)} = arg \\mathop{max}\\limits_\\theta Q(\\theta,\\theta^{(i)})$$\n",
    " \n",
    " （4）重复(2)(3),直至收敛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、EM算法的导出**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3、EM算法在无监督学习中的应用**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **二、EM算法的收敛性**  P201 - P203"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **三、EM算法在高斯混合模型学习中的应用** P203 - P207"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、高斯混合模型**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（高斯混合模型）** 高斯混合模型是指具有如下形式的概率分布模型：\n",
    "#### $$P(y|\\theta) = \\sum_{k=1}^K \\alpha_k\\phi(y|\\theta_k)$$\n",
    "\n",
    "其中，$\\alpha_k$ 是系数，$\\alpha_k \\geq 0, \\sum_{k=1}^K \\alpha_k =1; \\phi(y|\\theta_k)$ 是高斯密度函数， $\\theta_k = (\\mu_k,\\sigma_k^2)$\n",
    "#### $$\\phi(y|\\theta_k) = \\frac{1}{\\sqrt{2\\pi}\\sigma_k} exp\\Big(- \\frac{(y-\\mu_k)^2}{2\\sigma_k^2}\\Big)$$\n",
    "\n",
    "称为第 k 个分模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、高斯混合模型参数估计的EM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> $$ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ exp\\Big(-\\frac{(y_j-\\mu_k)^2}{2\\sigma_k^2}\\Big) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **三、EM算法的推广**   P207 - P211"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、F函数的极大-极大算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、GEM算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$exp\\Big(-frac{(y_j-\\mu_k)^2}{2\\sigma_k^2}\\Big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
