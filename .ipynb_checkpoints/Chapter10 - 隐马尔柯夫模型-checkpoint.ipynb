{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font><b>第十章 隐马尔可夫模型</b></font> P213-P234 ……22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、隐马尔可夫模型（hidden Markov model ,HMM) 是可用于标注问题的统计学习模型，描述由隐藏的马尔可夫链随机生成观测序列的过程，属于生成模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **一、隐马尔可夫模型的基本定义** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、隐马尔可夫模型的定义**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（隐马尔可夫模型）** 隐马尔可夫模型是关于时序的概率模型，描述由现代战争隐藏的马尔可夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测从而产生观测随机序列的过程。隐藏的马尔可夫链随机生成 的状态的序列，称为状态序列（state sequence);  每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列（observation sequence) 。 序列的每一个位置又可以看作是一个时刻。\n",
    "\n",
    "**隐马尔可夫模型由初始概率分布、状态转移概率分布以及观测概率分布确定。**\n",
    "\n",
    "**隐马尔可夫模型的形式定义如下：**\n",
    "\n",
    "设 $Q$ 是所有可能的状态的集合，$V$ 是所有可能的观测的集合：<font size=4>$Q = \\{q_1,q_2,\\cdots,q_N\\}, V = \\{v_1,v_2,\\cdots,v_M\\}$</font> ,$N$ 是可能的状态数，$M$ 是可能的观测数。\n",
    "\n",
    "$I$ 是长度为 $T$ 的状态序列， $O$ 是对应的观测序列： <font size=4>$I = (i_1,i_2,\\cdots,i_T), O = (o_1,o_2,\\cdots,o_T)$</font> \n",
    "\n",
    "$A$ 是状态转移概率矩阵 <font size=3>$A = [a_{ij}]_{N\\times N}$</font> 。其中，<font size=3>$ a_{ij} = P(i_{t+1} = q_j|i_t = q_i), i = 1,2,\\cdots,N;  j=1,2,\\cdots,N$</font> 是在时间 $t$ 处于状态 $q_i$ 的条件下在时刻 $t+1$ 转移到状态 $q_j$ 的概率。 （从一个状态转移到另一个状态的概率）\n",
    "\n",
    "$B$ 是观测矩阵： <font size=3>$ B = [b_j(k)]_{N\\times M}$</font> . 其中， <font size=3>$b_j(k) = P(o_t = v_k | i_t = q_j, k=1,2,\\cdots,M; j = 1,2,\\cdots,N$</font> 是在时刻 $t$ 处于 状态$q_j$ 的条件下 生成观测 $v_k$ 的概率。 (在某状态下，生成观测（即y）的概率)\n",
    "\n",
    "$\\pi$ 是初始状态概率向量 <font size=3> $\\pi = (\\pi_i) $</font> . 其中，<font size=3> $\\pi_i = P(i_1 = q_i) , i=1,2,\\cdots,N$ 是时刻 $t+1$ 处于状态$q_i$ 的概率。</font>\n",
    "\n",
    "<font size=3><i><b>隐马尔可夫模型由初始状态概率向量 $\\pi$ 、状态转移概率矩阵 $A$ 和观测概率矩阵 $B$ 决定</b></i></font> 。其中， $\\pi$ 和 $A$ 决定状态序列，确定了隐藏的马尔可夫链，生成不可观测的状态序列； $B$ 决定观测序列，确定了如何从状态生成观测，与状态序列综合确定了如何产生观测序列。\n",
    "\n",
    " <font size=3><b>隐马尔可夫模型 $\\lambda = (A,B,\\pi) ；A,B,\\pi$ 称为隐马尔可夫模型的三要素。</b></font>\n",
    " \n",
    "**隐马尔可夫模型做了两个基本假设：** (1) 齐次马尔可夫性假设，即假设隐藏的马尔可夫链在任意时刻 $t$ 的状态只依赖于前一时刻的状态，与其他时刻的状态及观测无关，也与时刻$t$无关； (2) 观测独立性假设，即假设任意时刻的观测只依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关； "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、观测序列的生成过程**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（观测序列的生成）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入： 隐马尔可夫模型 $\\lambda = (A,B,\\pi)$, 观测序列长度 $T$\n",
    "\n",
    "输出： 观测序列 $O = (o_1,o_2,\\cdots,o_T)$\n",
    "\n",
    " （1）按照初始初始状态分布 $\\pi$ 产生状态 $i_1$\n",
    " \n",
    " （2）令t=1;\n",
    " \n",
    " （3）按照状态 $i_t$ 的观测概率分布 <font size=3>$b_{i_t}(k)$</font> 生成 <font size=3>$o_t$</font>\n",
    " \n",
    " （4）按照状态 $i_t$ 的状态转移概率分布 <font size=3>$ \\{a_{i_t}i_{t+1}\\} $</font> 产生状态 $i_{t+1}, i_{t+1} = 1,2,\\cdots,N$\n",
    " \n",
    " （5）令 $t = t + 1$ ;  如果 $t<T$ , 转至（3）；否则终止；\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3、隐马尔可夫模型的3个基本问题**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）**概率计算问题** 给定模型 $\\lambda = (A,B,\\pi)$  和观测序列 $O = (o_1,o_2,\\cdots, o_T)$， 计算模型 $\\lambda$ 下观测序列 $O$出现的概率 $P(O|\\lambda)$\n",
    "\n",
    "（2）**学习问题** 已知观测序列 $O = (o_1,o_2,\\cdots, o_T)$ , 估计模型 $\\lambda = (A,B,\\pi)$ 参数，使该模型下观测序列$P(O|\\lambda)$ 最大。即用极大似然估计的方法估计参数。\n",
    "\n",
    "（3）**预测问题，也称为解码（decoding）问题** 已知 $\\lambda = (A,B,\\pi)$ 和观测序列 $O = (o_1,o_2,\\cdots, o_T)$， 求对给定观测序列条件概率 $P(I|O)$ 最大的状态序列 $I = (i_1,i_2,\\cdots,i_T)$ 。 即给定观测序列，求最有可能的对应的状态序列。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **二、概率计算算法**  P217"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、直接计算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "概念上可行，但是计算上不可行的直接计算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、前向算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（前向概率）** 给定隐马尔可夫模型 $\\lambda$ ，定义到时刻 $t$ 部分观测序列为 $o_1,o_2,\\cdots,o_t$ 且 状态为 $q_i$ 的概率为前向概率，记为 \n",
    "#### $$ a_t(i) = P(o_1,o_2,\\cdots,o_t, i_t = q_i |\\lambda) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（观测序列概率的前向算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：隐马尔可夫模型 $\\lambda(A,B,\\pi)$ ， 观测序列 $O$ ； 其中，$A$ 状态转移矩阵，$B$ 观测概率矩阵，$\\pi$ 初始状态矩阵\n",
    "\n",
    "输出：观测序列概率 $P(O|\\lambda)$\n",
    "\n",
    " （1）初值 <font size=3>$a_1(i) = \\pi_i b_i(o_1),\\quad i=1,2,\\cdots,N$</font>\n",
    " \n",
    " （2）递推 对 $t = 1,2,\\cdots,T-1$ :  <font size=4>$ a_{t+1}(i) = \\big[\\sum_{j=1}^N a_t(j)a_{ji}\\big]b_i(o_{t+1}),\\quad i=1,2,\\cdots,N $</font>\n",
    " \n",
    " （3）终止 <font size = 4> $ P(O|\\lambda) = \\sum_{i=1}^N a_T(i)$</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "**解读：**\n",
    "\n",
    "1）初始值 <font size=3>$a_1(i) = [\\pi_1 B[1,o_1],\\pi_2 B[2,o_1],\\cdots, \\pi_N B[N,o_1]] ,B[i,o_1] $</font> 表示观测概率矩阵的某个值 第$i$ 行，列由$o_1$ 即观测序列中的值决定，即从各个状态，取到观测值$o_1$的概率   $\\Rightarrow \\pi \\bullet mat(B 第O[0]列)$\n",
    "\n",
    "2) 后 T-1个时刻，第t+1时刻，各状态的概率 $ a_{t+1} $ 依赖于当前时刻的状态转移矩阵 $B[i,O_{t+1}]$ 以及 前一个时刻 各个状态的概率<font size=4> $a_t$ </font> \n",
    "   $\\sum_{j=1}^N a_t(j)a_{ji} = mat(a_t)\\bullet mat(A_i) \\Rightarrow 当前时刻(t+1)第 i 个状态的概率 = [前一时刻(t)各状态的概率矩阵 a_t ]\\bullet [状态转移矩阵中，各状态转移到状态i的概率]$ \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"exp101.png\" width = 600 height=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 3 T: 4\n",
      "t= 0 当前时刻各状态概率： [0.1  0.16 0.28]\n",
      "t= 1 当前时刻各状态概率： [0.077  0.1104 0.0606]\n",
      "t= 2 当前时刻各状态概率： [0.04187  0.035512 0.052836]\n",
      "t= 3 当前时刻各状态概率： [0.021078 0.025188 0.013824]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06009079702198505"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "A = pd.DataFrame([[0.5,0.2,0.3], [0.3,0.5,0.2],[0.2,0.3,0.5]])\n",
    "B =pd.DataFrame([ [0.5,0.5], [0.4,0.6], [0.7,0.3]],columns=[\"红\",\"白\"])\n",
    "pi = np.array([0.2,0.4,0.4]).T\n",
    "O = np.array([\"红\",\"白\",\"红\",\"白\"])  # 0:红 1：白\n",
    "\n",
    "def prob_forward(A,B,pi,O):    \n",
    "    _alpha = []\n",
    "    N = A.shape[0]\n",
    "    T = len(O)\n",
    "\n",
    "    print(\"N:\",N,\"T:\",T)\n",
    "\n",
    "    for t in range(T):\n",
    "        _a = []\n",
    "\n",
    "        if t == 0 :\n",
    "        # 初值 \n",
    "            _a =  np.array([pi[i]*B.loc[i,O[t]] for i in range(N)],dtype=np.float32)   ## pi * 概率矩阵矩阵 B第O[t]列\n",
    "            _alpha.append(_a)\n",
    "        else:\n",
    "            for i in range(N):\n",
    "                temp = np.sum(np.array([ _alpha[t-1][j] * A.loc[j][i] for j in range(N) ] ,dtype=np.float32))\n",
    "                _a.append(temp*B.loc[i][O[t]])\n",
    "            _alpha.append(_a)\n",
    "\n",
    "        print(\"t=\",t,\"当前时刻各状态概率：\", np.round(_a,6))\n",
    "\n",
    "    return np.sum(_alpha[T-1])\n",
    "            \n",
    "prob_forward(A,B,pi,O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3、后向算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（后向概率）** 给定隐马尔可夫模型 $\\lambda$，定义 在时刻$t$ 状态为 $q_i$ 的条件下，从$t+1$ 到 $T$的部分观测序列为 $o_{t+1},o_{t+2},\\cdots,o_{T}$ 的后向概率，记作 <font size=4>$ \\beta_t(i) = P(o_{t+1},o_{t+2},\\cdots,o_{T}|i_t = q_i,\\lambda) $</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（观测序列概率的后向算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：隐马尔可夫模型 $\\lambda(A,B,\\pi)$ ， 观测序列 $O$ ； 其中，$A$ 状态转移矩阵，$B$ 观测概率矩阵，$\\pi$ 初始状态矩阵\n",
    "\n",
    "输出：观测序列概率 $P(O|\\lambda)$\n",
    "\n",
    " （1）$\\beta_T(i) = 1,\\quad i = 1,2,\\cdots,N$\n",
    " \n",
    " （2）对 $t = T-1,T-2,\\cdots,1$ <font size=4>$\\quad \\beta_t(i) = \\sum_{j=1}^N\\alpha_{ij}b_j(o_{t+1})\\beta_{t+1}(j),\\quad i=1,2,\\cdots,N $</font> \n",
    " \n",
    " （3）<font size=4>$P(O|\\lambda) = \\sum_{i=1}^N \\pi_ib_i(o_1)\\beta_1(i)$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 [1. 1. 1.]\n",
      "2 [0.46 0.51 0.43]\n",
      "1 [0.2461 0.2312 0.2577]\n",
      "0 [0.112462 0.121737 0.104881]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.05304879999999999"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob_backward(A,B,pi,O): \n",
    "    \n",
    "    T = len(O)\n",
    "    N = A.shape[0]\n",
    "    beta = np.zeros((T,N))\n",
    "\n",
    "    for k in range(T,0,-1):\n",
    "        t = k -1\n",
    "        if t == T - 1:\n",
    "            beta[t] = [1]*N\n",
    "        else:\n",
    "            for i in range(N):\n",
    "                for j in range(N):\n",
    "                    beta[t][i] += A.loc[i,j] * B.loc[j,O[t+1]] * beta[t+1][j]\n",
    "        print(t,beta[t])\n",
    "\n",
    "    result = np.sum(np.array([pi[i] * B.loc[i,O[1]] * beta[0][i] for i in range(N)]))\n",
    "    return result\n",
    "prob_backward(A,B,pi,O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **三、学习算法**  P223"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据训练数据是包括观测序列和对应的状态序列，还是只有观测序列，可以分为监督学习和无监督学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、监督学习方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设已给训练数据包括 $S$ 个长度相同的观测序列和对应的状态序列 $\\{(O_1,I_1),(O_2,I_2),\\cdots,(O_S,I_S),\\}$ ,那么 可以利用极大似然估计法来估计隐马尔可夫模型的参数。具体方如下：\n",
    "\n",
    "（1）**转移概率 $\\alpha_{ij}$ 的估计** 设样本中时刻 $t$ 处于状态 $i$，时刻  $t+1$ 转移到状态 $j$ 的频数为 $A_{ij}$， 那么状态转移概率 $\\alpha_ij$ 的估计是\n",
    "#### $$\\hat{\\alpha}_{ij} = \\frac{A_{ij}}{\\sum_{j=1}^N A_{ij}},\\quad i,j=1,2,\\cdots,N$$\n",
    "\n",
    "（2）**观测概率 $b_j(k)$ 的估计** 设样本中状态为$j$ 并观测为 $k$ 的频数是 $B_{jk}$ , 那么状态为$j$ 观测为 $k$的概率 $b_j(k)$ 的估计是 \n",
    "#### $$\\hat{b}_{jk} = \\frac{B_{jk}}{\\sum_{k=1}^M B_{jk}},\\quad j = 1,2,\\cdots,N; \\quad k = 1,2,M$$\n",
    "\n",
    "（3）初始状态概率 $\\pi_i$ 的估计 $\\hat{\\pi}_i$ 为 $S$ 个样本中初始状态为 $q_i$ 的频率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、Baum-Welch算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设给定训练数据只包含$S$ 个长度为 $T$ 的观测序列 $O = \\{O_1,O_2,\\cdots,O_S\\}$ 而没有对应的状态序列；目标是学习隐马尔可夫模型 $\\lambda = (A,B,\\pi) $ 的参数。 将状态序列数据看作不可观测的隐数据 $I$, 那么马尔可夫模型事实上是一个含有隐变量的概率模型\n",
    "#### $$P(O|\\lambda) = \\sum_I P(O|I,\\lambda)P(I|\\lambda)$$ \n",
    "它的参数学习可以由EM算法实现。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）**确定完全数据的对数似然函数** 所有观测数据写成 <font size=4>$O = \\{O_1,O_2,\\cdots,O_T\\}$ </font>, 所有隐数据写成 <font size=4>$I = \\{i_1,i_2,\\cdots,i_T\\}$</font>, \n",
    "完全数据是 <font size=4>$(O,I) = (O_1,O_2,\\cdots,O_T,i_1,i_2,\\cdots,i_T)$</font> 。完全数据的对数似然函数是 <font size=4>$logP(O,I|\\lambda)$</font>\n",
    "\n",
    "（2）EM算法E步： 求 $Q$ 函数 <font size=4> $Q(\\lambda,\\bar{\\lambda}) = \\sum_I logP(O,I|\\lambda)P(O,I|\\bar{\\lambda})$ </font> \n",
    "\n",
    "<font><i><b> 注：$logP(O,I|\\lambda)$ 表示在给定模型 $\\lambda$ 下，观测序列 $O$ 和 状态序列 $I$的联合概率 </b></i></font>\n",
    "\n",
    "其中，$\\bar{\\lambda}$ 是隐马尔可夫模型参数的当前估计值， $\\lambda$ 是要极大化的隐马尔可夫模型参数。\n",
    "\n",
    "#### $$P(O,I|\\lambda) = \\pi_{i_1}b_{i_1}(o_1)\\alpha_{i_1i_2}b_{i_2}(o_2)\\cdots \\alpha_{i_{T-1}i_T}b_{i_T}(o_T)$$\n",
    "于是，函数 \n",
    "#### $$\\begin{align} Q(\\lambda,\\bar{\\lambda}) &= \\sum_I logP(O,I|\\lambda)P(O,I|\\bar{\\lambda}) \\\\\n",
    "                                              &= \\sum_I log(\\pi_{i_1}b_{i_1}(o_1)\\alpha_{i_1i_2}b_{i_2}(o_2)\\cdots \\alpha_{i_{T-1}i_T}b_{i_T}(o_T))P(O,I|\\bar{\\lambda})\\\\\n",
    "                                              &= \\sum_I log \\pi_{i_1}P(O,I|\\bar{\\lambda}) + \\sum_I \\Big(\\sum_{t=1}^{T-1}log \\alpha_{i_{t1}i_{t+1}}\\Big)P(O,I|\\bar{\\lambda}) + \\sum_I \\Big(\\sum_{t=1}^{T-1}log b_{i_T}(o_T)\\Big)P(O,I|\\bar{\\lambda}) \\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（3）EM算法的M步：极大化 Q 函数 $Q(\\lambda,\\bar{\\lambda})$ 求模型参数 $A,B,\\pi$\n",
    "\n",
    "**a) 上式第一项：**\n",
    "#### $$\\begin{align} & \\sum_I log \\pi_{i_1}P(O,I|\\bar{\\lambda}) = \\sum_{i=1}^N log \\pi_{i_1}P(O,I|\\bar{\\lambda})\\\\\n",
    "                     & s.t.\\quad \\sum_{i=1}^N \\pi = 1 \\end{align}$$\n",
    "拉格朗日函数 \n",
    "#### $$\\sum_{i=1}^N log \\pi_{i_1}P(O,I|\\bar{\\lambda}) + \\gamma (\\sum_{i=1}^N \\pi_i - 1) $$\n",
    "求偏导：\n",
    "#### $$\\frac{\\partial }{\\partial \\pi_i} \\Big[\\sum_{i=1}^N log \\pi_{i_1}P(O,I|\\bar{\\lambda}) + \\gamma (\\sum_{i=1}^N \\pi_i - 1)\\Big] = \\sum_{i=1}^N\\frac{P(O,i_1=i|\\bar{\\lambda})}{\\pi_i} + \\gamma = 0 \\Rightarrow \\gamma = -P(O|\\bar{\\lambda})$$\n",
    "代入原公式 得到：\n",
    "#### $$\\pi_i = \\frac{P(O,i_1 = i|\\bar{\\lambda})}{P(O|\\bar{\\lambda})}$$\n",
    "\n",
    "**b) 上式第二项：**\n",
    "#### $$\\begin{align} & \\sum_I \\Big(\\sum_{t=1}^{T-1}log \\alpha_{i_{t1}i_{t+1}}\\Big)P(O,I|\\bar{\\lambda}) = \\sum_{i=1}^N \\sum_{j=1}^N \\sum_{t=1}^{T-1}log\\alpha_{ij}P(O,i_t=i,i_{t+1}=j|\\bar{\\lambda})\\\\\n",
    "                     & s.t.  \\sum_{j=1}^N\\alpha_{ij}=1 \\end{align}$$\n",
    "#### $$\\Rightarrow \\alpha_{ij} = \\frac{\\sum_{t=1}^{T-1}P(P,i_t = i ,i_{t+1} = j |\\bar{\\lambda})}{\\sum_{t=1}^{T-1}P(O,i_t = i |\\bar{\\lambda})}$$\n",
    "\n",
    "**b) 由上式第三项得：**\n",
    "#### $$b_j(k) = \\frac{\\sum_{t=1}^T P(O,i_t = j|\\bar{\\lambda})I(o_t = v_k)}{\\sum_{t=1}^TP(O,i_t = j |\\bar{\\lambda})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（Baum-Welch算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：观测数据 $O = (o_1,o_2,\\cdots,o_T)$\n",
    "\n",
    "输出：隐马尔可夫模型参数 $A,B,\\pi$\n",
    "\n",
    " （1）初始化。对 $n=0$，选取 <font size=4> $\\alpha_{ij}^{(0)},b_j(k)^{(0)},\\pi_i^{(0)} $ </font>, 得到模型 <font size=4> $ \\lambda^{(0)} = (A^{(0)}, B^{(0)} , \\pi^{(0)})$</font>\n",
    " \n",
    " （2）递推。对 $n = 1,2,\\cdots, $\n",
    " ### $$\\alpha_{ij}^{(n+1)} = \\frac{\\sum\\limits_t^{T-1} \\xi_t(i,j)}{\\sum\\limits_t^{T-1} \\gamma_t(i)},\\quad b_j(k)^{(n+1)} = \\frac{\\sum\\limits_{t=1,o_t=v_k}^{T} \\gamma_t(j)}{\\sum\\limits_t^{T-1} \\gamma_t(j)},\\quad \\pi_i^{(n+1)} = \\gamma_1(i)$$\n",
    " \n",
    " 其中，给定模型 $\\lambda$ 和观测$O$ ， 在时刻 $t$ 处于状态 $q_i$的概率： \n",
    " #### $$\\gamma_t(i) = P(i_t = q_i|O,\\lambda) = \\frac{P(i_t = q_i,O|\\lambda)}{P(O|\\lambda)} = \\frac{\\alpha_t(i)\\beta_t(i) }{P(O|\\lambda)} \\Big (\\because \\alpha_t(i)\\beta_t(i) = P(i_t = q_i,O|\\lambda)\\Big)  = \\frac{\\alpha_t(i)\\beta_t(i) }{\\sum_{j=1}^N\\alpha_t(j)\\beta_t(j)} $$\n",
    " \n",
    "给定模型 $\\lambda$ 和观测$O$ ， 在时刻 $t$ 处于状态 $q_i$的概率，在时刻 $t+1$ 处于状态 $q_j$ 的概率：\n",
    "#### $$\\xi_t(i,j) = P(i_t = q_i, i_{t+1} = q_j | O,\\lambda) = \\frac{ P(i_t = q_i, i_{t+1} = q_j,O|\\lambda) }{P(O|\\lambda)} = \\frac{ P(i_t = q_i, i_{t+1} = q_j,O|\\lambda)  }{ \\sum_{i=1}^N \\sum_{j=1}^N P(i_t = q_i,i_{t+1} = q_j, O|\\lambda)} = \\frac{\\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)}{ \\sum_{i=1}^N \\sum_{j=1}^N \\alpha_t(i)a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)} \\quad \\because P(i_t = q_i, i_{t+1} = q_j,O|\\lambda) = \\alpha_i a_{ij}b_j(o_{t+1})\\beta_{t+1}(j)$$\n",
    "\n",
    " （3）终止。 得到参数模型 <font size=4> $\\lambda^{(n+1)} = \\big(A^{(n+1)},B^{(n+1)},\\pi^{(n+1)}\\big)$ </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **四、预测算法**  P227"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1、近似算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2、维特比算法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "维比特算法实际是用动态规划（dynamic programming）解隐马尔可夫模型的预测问题，即用动态规划求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。\n",
    "\n",
    "从时刻 $t=1$开始，递推地计算时刻 $t$ 状态为 $i$的各条部分路径的最大概率，直到得到时刻 $t=T$ 状态为 $i$ 的各条路径的最大概率（即最优路径的概率 $P^*$，最优路径的终点也同时得到。 之后，为了找出最优路径的各个节点，从终结点 $i_T^*$ 开始，由后向前求得结点 $i_{T-1}^*,\\cdots,i_1^*$， 得到最优路径 $I^* = (i_1^*,i_2^*,\\cdots,i_T^*)$\n",
    "\n",
    "定义在时刻 $t$ 状态为 $i$ 的所有单个路径 $(i_1,i_2,\\cdots,i_t)$ 中概率 最大值为\n",
    "### $$\\begin{align} & \\delta_t(i) = max_{i_1,i_2,\\cdots,i_{t-1}} P(i_t = i,i_{t-1},\\cdots,i_1,o_t,\\cdots,o_1|\\lambda),i=1,2,\\cdots,N\\\\\n",
    "\\Rightarrow & \\delta_{t+1}(i) = max_{i_1,i_2,\\cdots,i_{t-1}} P(i_{i+1} = i,i_{t},\\cdots,i_1,o_{t+1},\\cdots,o_1|\\lambda) \\\\ & = \\mathop{max}\\limits_{1\\leq j\\leq N} [ \\delta_t(j)a_{ji}]bi(o_{t+1}),\\quad i=1,2,\\cdots,N; t = 1,2,\\cdots,T-1 \\end{align}$$\n",
    "\n",
    "定义在时刻 $t$ 状态为 $i$ 的所有单个路径 $(i_1,i_2,\\cdots,i_t)$ 中概率 最大的路径的第 $t-1$个结点为\n",
    "#### $$\\Psi(i) = arg \\mathop{max}\\limits_{1\\leq j \\leq N} [\\delta_{t-1}(j)a_{ji}], i=1,2,\\cdots,N$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（维比特算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：模型 $\\lambda = (A,B,\\pi)$ 和观测 $O = (o_1,o_2,\\cdots,o_T)$\n",
    "\n",
    "输出：最优路径 $I^* = (i_1^*,i_2^*,\\dots,i_T^*)$\n",
    "\n",
    " （1）初始化   <font size=4>$\\delta_1(i) = \\pi_ib_i(o_1),\\quad \\Psi(i) = 0,i=1,2,\\cdots,N$</font>\n",
    " \n",
    " （2）递推 对 $t=2,3,\\cdots,T\\quad$, <font size=4>$\\delta_t(i) =\\mathop{max}\\limits_{1\\leq j\\leq N} [\\delta_{t-1}(j)a_{ji}]b_i(o_t),\\Psi_t(i) = arg\\mathop{max}\\limits_{1\\leq j \\leq N} [\\delta_{t-1}(j)a_{ji}], i=1,2,\\cdots,N $</font>\n",
    " \n",
    " （3）终止 <font size=4>$ P^* = \\mathop{max}\\limits_{1\\leq j \\leq N} \\delta_T(i) ,\\quad i_T^* = arg \\mathop{max}\\limits_{1\\leq j \\leq N} [\\delta_T(i)]$</font>\n",
    " \n",
    " （4）最优路径回溯。 对 $t=T-1,T-2,\\cdots,1$ <font size=4> $i_t^* = \\Psi_{t+1}(i_{t+1}^*)$ </font> 求得最佳路径 <font size=4> $I^* = (i_1^*,i_2^*,\\cdots,i_T^*) $</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**例**\n",
    "<img src = \"exp10.3.png\" width = 400 height=250></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 3\n",
      "t =  0\n",
      "\t 各状态取出[ 红 ]的概率： [0.1  0.16 0.28]\n",
      "[[0.1  0.   0.   0.  ]\n",
      " [0.16 0.   0.   0.  ]\n",
      " [0.28 0.   0.   0.  ]]\n",
      "t =  1\n",
      "上一时刻各状态的概率： [0.1  0.16 0.28]\n",
      "上一时刻各状态 -> 当前时刻各状态的概率：\n",
      "[[0.025  0.012  0.009 ]\n",
      " [0.024  0.048  0.0096]\n",
      " [0.028  0.0504 0.042 ]]\n",
      "当前状态: 0 上一状态到当前状态的最大概率: 0.028\n",
      "最大概率对应的上一个状态： 2\n",
      "当前状态: 1 上一状态到当前状态的最大概率: 0.0504\n",
      "最大概率对应的上一个状态： 2\n",
      "当前状态: 2 上一状态到当前状态的最大概率: 0.042\n",
      "最大概率对应的上一个状态： 2\n",
      "t =  2\n",
      "上一时刻各状态的概率： [0.028  0.0504 0.042 ]\n",
      "上一时刻各状态 -> 当前时刻各状态的概率：\n",
      "[[0.007    0.00224  0.00588 ]\n",
      " [0.00756  0.01008  0.007056]\n",
      " [0.0042   0.00504  0.0147  ]]\n",
      "当前状态: 0 上一状态到当前状态的最大概率: 0.0076\n",
      "最大概率对应的上一个状态： 1\n",
      "当前状态: 1 上一状态到当前状态的最大概率: 0.0101\n",
      "最大概率对应的上一个状态： 1\n",
      "当前状态: 2 上一状态到当前状态的最大概率: 0.0147\n",
      "最大概率对应的上一个状态： 2\n",
      "t =  3\n",
      "上一时刻各状态的概率： [0.00756 0.01008 0.0147 ]\n",
      "上一时刻各状态 -> 当前时刻各状态的概率：\n",
      "[[0.00189   0.0009072 0.0006804]\n",
      " [0.001512  0.003024  0.0006048]\n",
      " [0.00147   0.002646  0.002205 ]]\n",
      "当前状态: 0 上一状态到当前状态的最大概率: 0.0019\n",
      "最大概率对应的上一个状态： 0\n",
      "当前状态: 1 上一状态到当前状态的最大概率: 0.003\n",
      "最大概率对应的上一个状态： 1\n",
      "当前状态: 2 上一状态到当前状态的最大概率: 0.0022\n",
      "最大概率对应的上一个状态： 2\n",
      "最优路径概率： 0.003 最优路径： [2. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "A = pd.DataFrame([[0.5,0.2,0.3], [0.3,0.5,0.2],[0.2,0.3,0.5]])\n",
    "B =pd.DataFrame([ [0.5,0.5], [0.4,0.6], [0.7,0.3]],columns=[\"红\",\"白\"])\n",
    "pi = np.array([0.2,0.4,0.4]).T\n",
    "O = np.array([\"红\",\"白\",\"红\",\"白\"])  # 0:红 1：白\n",
    "\n",
    "\n",
    "# def prob_forward_backward(A,B,O,pi):\n",
    "T = len(O)\n",
    "N = A.shape[1]\n",
    "print(T,N)\n",
    "\n",
    "# 存储 t（t<=T） 时刻，状态为 i 的所有单个路径中概率中概率最大的值\n",
    "# 以例10.3为例，时刻 t2中，\n",
    "# max{ P(时刻t1&状态3 -> 时刻t2&状态3 & 取出o[2]即白球)，\n",
    "#      P(t1&状态1 -> 时刻t2&状态3 & 白球)，\n",
    "#      P(t1&状态1 -> 时刻t2&状态3 & 白球)\n",
    "#     } = 0.042\n",
    "delta = np.zeros((N,T)) \n",
    "\n",
    "# 存储 在 t 时刻，状态为i的所有单个路径中概率最大的路径的第t-1个节点\n",
    "# 见上，存储 t3状态3 最大概率=0.042 对应的t1状态（即状态3）\n",
    "psi = np.zeros((N,T)) #\n",
    "\n",
    "for t in range(T):\n",
    "    print(\"t = \",t)\n",
    "    if t == 0:\n",
    "        temp_delta = [pi[i]*B.loc[i][O[t]] for i in range(N)]  ## 初值，计算N个状态中，取出O[t]（eg.10.3 红球）的概率        \n",
    "        print(\"\\t\",\"各状态取出[\",O[t],\"]的概率：\",np.round(temp_delta,2))\n",
    "        delta[:,t] = temp_delta\n",
    "        print(delta)\n",
    "        ## psi[:,t] = list(delta[:,t]).index(np.max(delta[:,t]))\n",
    "    else:\n",
    "        last_delta = delta[:,t-1] ## 上一个时刻各状态的概率\n",
    "        print(\"上一时刻各状态的概率：\",last_delta)\n",
    "        \n",
    "        print(\"上一时刻各状态 -> 当前时刻各状态的概率：\")\n",
    "        tempA = np.zeros((N,N))\n",
    "        for j in range(N): ## 上一时刻状态\n",
    "            for i in range(N): ## 当前时刻状态\n",
    "                tempA[j,i] = delta[j,t-1] * A.loc[j,i]*B.loc[i,O[t]]  ## A.loc[j,i]：从状态j转移到状态i的概率，B.loc[i,O[t]]: 从状态i \n",
    "        print(tempA)\n",
    "        \n",
    "        for k in range(N):\n",
    "            max_prob = np.max(tempA[:,k])\n",
    "            print(\"当前状态:\",k,\"上一状态到当前状态的最大概率:\",np.round(max_prob,4))\n",
    "            \n",
    "            max_prob_state = list(tempA[:,k]).index(np.max(tempA[:,k])) # 最大概率 对应的上一个时刻的状态\n",
    "            print(\"最大概率对应的上一个状态：\", max_prob_state)\n",
    "            \n",
    "            delta[k,t] =  max_prob\n",
    "            psi[k,t] = max_prob_state \n",
    "        \n",
    "# 终止 \n",
    "I = np.zeros(T) # 存储\n",
    "\n",
    "#最终最大概率 ：\n",
    "max_prob = np.max(delta[:,T-1])\n",
    "\n",
    "\n",
    "# I[T-1] = list(delta[:,T-1]).\n",
    "\n",
    "for t in range(T-1,-1,-1):\n",
    "    if t==T-1:\n",
    "        I[t] = list(delta[:,t]).index(np.max(delta[:,t]))\n",
    "    else:\n",
    "        I[t] = psi[np.int(I[t+1])][t+1]\n",
    "        \n",
    "print(\"最优路径概率：\",round(max_prob,4),\"最优路径：\",I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"exp10.2.png\" width = 600 height=400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
