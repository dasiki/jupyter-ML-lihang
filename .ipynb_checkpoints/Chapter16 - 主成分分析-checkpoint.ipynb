{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font><b>第十六章 主成分分析 </b></font> P317 - P340…… 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "1、主成分分析（principal component analysis,PCA）是一种常用的无监督学习方法，这一方法**利用正交变换把由线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分**\n",
    "\n",
    "2、主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。\n",
    "\n",
    "3、主成分分析主要用于发现数据中的基本结构，即数据中变量之间的关系，是数据分析的有力工具。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **一、总体主成分分析**  P317 - P329 … 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、数据的变量之间可能存在相关性，以致增加了分析的维度。于是，考虑由少数不相关的变量来代替相关的变量，用来表示数据，并要求能够保留数据中的大部分信息。\n",
    "\n",
    "2、**主成分分析的基本思想** 主成分分析中，首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为1。之后，对数据进行正交变换，原来由线性相关变量表示的数据，通过正交变换，变成由若干线性无关的新变量表示的数据。 新变量是可能 的正交变换中，变量的方差的和（信息存在）最大的，方差表示在新变量上信息的大小。将新变量依次称为第一主成分、第二主成分等。\n",
    "\n",
    "3、通过主成分分析，可以利用主成分近似地表示原始数据，这可理解为发现数据的“基本结构” \n",
    "\n",
    "4、也可以把数据由少数主成分表示，这可理解为对数据降维。\n",
    "\n",
    "5、数据集合中的样本由实数空间（正交坐标系）中的点表示，空间的一个坐标轴表示一个变量，规范化处理后得到的数据分布在原点附近。**对原坐标系中的数据进行主成分分析，等价于进行坐标系旋转变换，将数据投影到新坐标系的坐标轴上**；新坐标系的第一坐标轴、第二坐标轴分析表示第一、第二主成分；数据在每一轴上的坐标值的平方表示相应变量的方差，并且，这个坐标系是在所有可能的新的坐标系中，坐标轴上的方差的和最大的。\n",
    "\n",
    "6、在数据总体（population）上进行的主成分分析称为总体主成分分析，在有限样本上进行的主成分分析称为样本主成分分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义和导出**\n",
    "\n",
    "假设 $x = (x_1,x_2,\\cdots,x_m)^T$ 是 $m$ 维随机变量，其均值向量是 $\\mu$ ：$\\mu = E(x) = (\\mu_1,\\mu_2,\\cdots,\\mu_m)^T$， \n",
    "\n",
    "协方差矩阵是 $\\Sigma$： $\\Sigma = cov(x,x) = E[(x-\\mu)(x-\\mu)^T] $ \n",
    "\n",
    "考虑由 $m$ 维随机变量 $x$ 到 $m$ 维随机变量 $y = (y_1,y_2,\\cdots,y_m)^T$ 的线性变换，<font size=4> $y_i = \\alpha_i^T x = \\alpha_{1i}x_1 + \\alpha_{2i}x_2 + \\cdots + \\alpha_{mi}x_m$ </font> 其中，<font size=4> $\\alpha_i^T = (\\alpha_{1i},\\alpha_{2i},\\cdots,\\alpha_{mi}), i=1,2,\\cdots,m$ </font>\n",
    "\n",
    "由随机变量的性质可知，\n",
    "#### $$ \\begin{align} & E(y_i) = \\alpha_i^T \\mu, \\quad i=1,2,\\cdots,m \\\\\n",
    "                      & var(y_i) = \\alpha_i^T\\Sigma \\alpha_i, \\quad i=1,2,\\cdots,m \\\\\n",
    "                      & cov(y_i,y_j) = \\alpha_i^T\\Sigma \\alpha_j,\\quad i,j = 1,2,\\cdots,m \\end{align}$$ \n",
    "\n",
    "\n",
    "**定义（总体主成分）** 考虑由 $m$ 维随机变量 $x$ 到 $m$ 维随机变量 $y = (y_1,y_2,\\cdots,y_m)^T$ 的线性变换，<font size=4> $y_i = \\alpha_i^T x = \\alpha_{1i}x_1 + \\alpha_{2i}x_2 + \\cdots + \\alpha_{mi}x_m$ </font>，如果它们满足以下条件：\n",
    "\n",
    "（1）系数向量 $\\alpha_i^T$ 是单位向量，即 $\\alpha_i^T \\alpha_i = 1, i=1,2,\\cdots,m$ \n",
    "\n",
    "（2）变量 $y_i$ 与 $y_j$ 互不相关，即 $cov(y_i,y_j) = 0 (i\\neq j)$ \n",
    "\n",
    "（3）变量 $y_1$ 是 $x$ 的所有线性变换中方差最大的； $y_2$ 是与 $y_1$ 不相关的 $x$ 的所有线性变换中方差最大的；一般地， $y_i$ 是与 $y_1,y_2,\\cdots,y_{i-1} (i=1,2,\\cdots,m)$ 都不相关的 $x$ 的所有线性变换中方差最大的；这时分别称 $y_1,y_2,\\cdots,y_m$ 为 $x$ 的第一主成分、第二主成分、 $\\cdots$、第 $m$ 主成分。\n",
    "\n",
    "**定理** 设 $x$ 是 $m$ 维随机变量， $\\Sigma$ 是 $x$ 的协方差矩阵， $\\Sigma$ 的特征值分别是 $\\lambda_1\\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_m \\geq 0$，特征值对应的单位特征向量分别是 $\\alpha_1,\\alpha_2,\\cdots,\\alpha_m$，则 $x$ 的第 $k$ 主成分是 \n",
    "#### $$ y_k = \\alpha_k^Tx = \\alpha_{1k}x_1 + \\alpha_{2k}x_2 + \\cdots + \\alpha_{mk}x_m,\\quad k=1,2,\\cdots,m$$ \n",
    "x 的第 $k$ 主成分的方差是\n",
    "#### $$var(y_k) = \\alpha_k^T \\Sigma \\alpha_k = \\lambda_k,\\quad k=1,2,\\cdots,m $$\n",
    "即协方差矩阵 $\\Sigma$ 的第 $k$ 个特征值。\n",
    "\n",
    "**推论** $m$ 维随机变量 $y = (y_1,y_2,\\cdots,y_m)^T$ 的分量依次是 $x$ 的第一主成分到第 $m$ 主成分的充要条件是：\n",
    "\n",
    "（1）$y=A^Tx$， $A$ 为正交矩阵 \n",
    "#### $$A = \\left[ \\begin{align} &\\alpha_{11}&\\quad&\\alpha_{12}&\\quad&\\cdots&\\quad&\\alpha_{1m}\\\\\n",
    "                                &\\alpha_{21}&\\quad&\\alpha_{22}&\\quad&\\cdots&\\quad&\\alpha_{2m}\\\\\n",
    "                                &\\vdots     &\\quad&\\vdots     &\\quad&\\quad &\\quad&\\vdots     \\\\\n",
    "                                &\\alpha_{m1}&\\quad&\\alpha_{m2}&\\quad&\\cdots&\\quad&\\alpha_{mm} \\end{align}\\right]$$ \n",
    "（2）$y$ 的协方差矩阵的对角矩阵 \n",
    "#### $$\\begin{align} & cov(y) = diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m) \\\\ & \\lambda_1 \\geq \\lambda_2 \\geq \\cdots \\geq \\lambda_m  \\end{align}$$ \n",
    "其中，$\\lambda_m$ 是 $\\Sigma$ 的第 $k$ 个特征值， $\\alpha_k$ 是对应的特征向量， $k=1,2,\\cdots,m$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> **总体主成分的性质** </font>\n",
    "\n",
    "（1） 总体主成分 $y$ 的协方差矩阵是对角矩阵 $cov(y) = \\wedge = diag(\\lambda_1,\\lambda_2,\\cdots,\\lambda_m) $ \n",
    "\n",
    "（2） 总体主成分 $y$ 的方差之和等于随机变量 $x$ 的方差之和，即  <font size=4 >$\\sum\\limits_{i=1}^m \\lambda_i = \\sum\\limits_{i=1}^m \\sigma_{ii}$ </font> ， 其中 $\\sigma_{ii}$ 是随机变量 $x_i$ 的方差，即协方差矩阵 $\\Sigma$ 的对角元素。利用矩阵的迹（trace） 及公式 $\\Sigma = A\\wedge A^T$ 可知， <font size=4> $\\sum_{i=1}^m var(x_i) = tr(\\Sigma^T) = tr ((A\\wedge A^T)^T) = tr(A^T \\wedge A) = tr(\\wedge) = \\sum\\limits_{i=1}^m \\lambda_i = \\sum\\limits_{i=1}^m var(y_i)$ </font> \n",
    "\n",
    "（3） 第 $k$ 个主成分 $y_k$ 与变量 $x_i$ 的相关系数 $\\rho(y_k,x_i)$ 称为因子负荷量（factor loading），它表示第 $k$ 个主成分 $y_k$ 与变量 $x_i$ 的相关关系。计算公式：\n",
    "#### $$ \\rho(y_k,x_i) = \\frac{\\sqrt{\\lambda_k}\\alpha_{ik}}{\\sqrt{\\sigma_{ii}}},\\quad k,i = 1,2,\\cdots,m$$ \n",
    "因为 \n",
    "#### $$ \\rho(y_k,x_i) = \\frac{ cov(y_k,x_i)}{ \\sqrt{var(y_k)var(x_i)}} = \\frac{ cov(\\alpha_k^T x, e_i^T x) }{ \\sqrt{\\lambda_k} \\sqrt{\\sigma_{ii}} }$$ \n",
    "其中，$e_i$ 为单位向量，其第 $i $ 个分量为1，其余为0。 再由协方差的性质：<font size=4> $cov(\\alpha_k^Tx,e_i^T x) = \\alpha_k^T \\Sigma e_i = e_i^T \\Sigma \\alpha_k = \\lambda_k e_i^T\\alpha_k = \\lambda_k \\alpha_{ik}$ </font> 得到，\n",
    "#### $$ \\rho(y_k,x_i) = \\frac{\\sqrt{\\lambda_k}\\alpha_{ik}}{\\sqrt{\\sigma_{ii}}},\\quad k,i = 1,2,\\cdots,m$$ \n",
    "\n",
    "（4） 第 $k$ 个主成分 $y_k$ 与 $m$ 个变量的因子负荷量满足\n",
    "#### $$ \\sum_{i=1}^m \\sigma_{ii}\\rho^2(y_k,x_i) = \\sum_{i=1}^m \\lambda_k\\alpha_{ik}^2 = \\lambda_k \\alpha_k^T \\alpha_k = \\lambda_k $$ \n",
    "\n",
    "（5） $m$ 个主成分 与第 $i$ 个变量 $x_i$ 的因子负荷量满足\n",
    "#### $$ \\sum_{i=1}^m\\rho^2 (y_k,x_i) = 1$$ \n",
    "$\\because y_1,y_2,\\cdots,y_m $ 互不相关，故 <font size=4> $\\rho^2(x_i,(y_1,y_2,\\cdots,y_m)) = \\sum_{k=1}^m \\rho^2(y_k,x_i)$</font>\n",
    "\n",
    "又因 $x_i$ 可以表示为 $y_1,y_2,\\cdots,y_m$ 的线性组合，所以 $x_i$ 与 $y_1,y_2,\\cdots,y_m$ 的相关系数的平方为1，即  $\\rho^2(x_i,(y_1,y_2,\\cdots,y_m)) = 1$ \n",
    "\n",
    "$\\therefore \\sum_{i=1}^m\\rho^2 (y_k,x_i) = 1$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4> **主成份的个数** </font>\n",
    "\n",
    "**定理16.2** 对任意正整数 $q,1\\leq q \\leq m$，考虑正交线性变换 $y = B^T x$ ；其中 $y$ 是 $q$ 维向量， $B^T $是 $m\\times n$ 矩阵，令 $y$ 的协方差矩阵是 $\\Sigma_y = B^T \\Sigma B$，则 $\\Sigma_y$ 的迹 $tr(\\Sigma_y)$ 在 $B = A_q$ 时取得最大值，其中矩阵 $A_q$ 由正交矩阵 $A$ 的前 $q$ 列组成。\n",
    "\n",
    "上述定理表明，当 $x$ 的线性变换 $y$ 在 $B=A_q$时，其协方差矩阵 $\\Sigma_y$ 的迹 $tr(\\Sigma_y)$ 取得最大值，即当取 $A$ 的前 $q$ 列取 $x$ 的前 $q$ 个主成分时，能够最大限度 地保留原有变量方差的信息。\n",
    "\n",
    "**定理16.3** 考虑正交变换 $y = B^T x$，这里，$B^T$ 是 $p\\times m$ 矩阵， $A$ 和 $\\Sigma_y$ 的定义与定理16.2相同，则 $tr(\\sigma_y)$ 在 $B = A_p$ 时取得最小值，其中矩阵 $A_p$ 由 $A$ 的后 $p$ 列组成。\n",
    "\n",
    "定理16.3 可以理解为，当舍弃 $A$ 的后 $p$ 列，即舍弃变量 $x$ 的后 $p$ 个主成分时，原有变量的方差信息损失最少。\n",
    "\n",
    "**以上两个定理可以作为选择 $k$ 个主成分的理论依据。具体选择 $k$ 的方法，通过利用方差贡献率。**\n",
    "\n",
    "**定义** 第 $k$ 个主成分 $y_k$ 的 **方差贡献率定义为** $ y_k$ 的方差与所有方差之和的比，记为 $\\eta_k$ \n",
    "#### $$\\eta_k = \\frac{\\lambda_k}{\\sum\\limits_{i=1}^m \\lambda_i}$$ \n",
    "$k$ 个主成分 $y_1,y_2,\\cdots,y_k$ 的累计方差贡献率定义为 $k$ 个方差之和与所有方差之和的比 \n",
    "#### $$ \\sum_{i=1}^m \\eta_i = \\frac{\\sum\\limits_{i=1}^k \\lambda_i}{\\sum\\limits_{i=1}^m \\lambda_i}$$ \n",
    "\n",
    "通常取 $k$ 使得累计方差贡献率达到规定的百分比以上，例如 70%-80%以上。 **累计方差贡献率反映了主成分保留信息的比例，但是它不能反映某个原有变量 $x_i$ 保留信息的比例，这时通常利用 $k$ 个主成分 $y_1,y_2,\\cdots,y_k$ 对原有变量 $x_i$ 的贡献率。** \n",
    "\n",
    "**定义** $k$ 个主成分 $y_1,y_2,\\cdots,y_k$ 对原有变量 $x_i$ 的贡献率定义为 $x_i$ 与 $(y_1,y_2,\\cdots,y_k)$ 的相关系数的平方，记作 $\\upsilon_i$ \n",
    "#### $$\\upsilon_i = \\rho^2(x_i,(y_1,y_2,\\cdots,y_k)$$ \n",
    "计算公式如下：\n",
    "#### $$ \\upsilon_i = \\rho^2(x_i,(y_1,y_2,\\cdots,y_k)) = \\sum_{j=1}^k \\rho^2(x_i,y_j) = \\sum_{j=1}^k \\frac{\\lambda_j \\alpha_{ij}^2}{\\sigma_{ii}}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **二、样本主成分分析**   P330 - P339 … 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ <font size=4> **相关矩阵的特征值分解算法** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定样本矩阵 $X$，**利用数据的样本协方差矩阵或者样本相关矩阵的特征值分解进行主成分分析**。具体步骤如下：\n",
    "\n",
    "（1）对观测数据进行规范化处理，得到规范化的数据矩阵，仍以 $X$ 表示\n",
    "#### $$ x_{ij}^* = \\frac{x_{ij} - \\bar{x}_i}{\\sqrt{s_{ii}}}$$ \n",
    "其中，\n",
    "#### $$\\begin{align} & \\bar{x}_i = \\frac{1}{n} \\sum_{j=1}^n x_{ij} , \\quad i=1,2,\\cdots,m \\\\ & s_{ii} = \\frac{1}{n-1} \\sum_{j=1}^n (x_{ij} - \\bar{x}_i)^2,\\quad i=1,2,\\cdots,m \\end{align}$$ \n",
    "（2）依据规范化数据矩阵，计算样本相关矩阵 $R$ \n",
    "#### $$R = [r_{ij}]_{m\\times n} = \\frac{1}{n=1}XX^T$$\n",
    "其中，<font size=4> $r_{ij}  = \\frac{1}{n-1} \\sum\\limits_{l=1}^n x_{il}x_{lj},\\quad i,j = 1,2,\\cdots,m$ </font>\n",
    "\n",
    "（3）求样本相关矩阵 $R$ 的 $k$ 个特征值和对应的 $k$ 个单位特征向量\n",
    "\n",
    "求解 $R$ 的特征方程 $|R - \\lambda I| = 0$ 得到 $R$ 的 $m$ 个特征值 $\\lambda_1 \\geq \\lambda_2\\geq \\cdots \\geq \\lambda_m$，求方差贡献率 $\\sum\\limits_{i=1}^k \\eta_i$ 达到预定值的主成分个数。\n",
    "\n",
    "求前 $k$ 个特征值对应的单位特征向量 $\\alpha_i = (\\alpha_{1i},\\alpha_{2i},\\cdots,\\alpha_{mi})^T,\\quad i = 1,2,\\cdots,k$ \n",
    "\n",
    "（4）求 $k$ 个样本主成分\n",
    "\n",
    "以 $k$ 个单位特征向量为系数进行线性变换，求出 $k$ 个样本主成分 $y_i = \\alpha_i^Tx, \\quad i=1,2,\\cdots,k$ \n",
    "\n",
    "（5）计算 $k$ 个主成分 $y_j$ 与原变量 $x_i$ 的相关系数  $\\rho(x_i,y_j)$，以及 $k$ 个主成分对原变量 $x_i$ 的贡献率 $\\upsilon_i$ \n",
    "\n",
    "（6）计算 $n$ 个样本的 $k$ 个成分值\n",
    "\n",
    "将规范化样本数据代入 $k$ 个主成分式： $y_i = \\alpha_i^Tx$ ，得到 $n$ 个样本的主成分值。第 $j$ 个样本 $x_j = (x_{1j},x_{2j},\\cdots,x_{mj})^T$ 的第 $i$ 个主成分值是\n",
    "#### $$ y_{ij} = (\\alpha_{1i},\\alpha_{2i},\\cdots,\\alpha_{mi}) (x_{1j},x_{2j},\\cdots,x_{mj})^T = \\sum\\limits_{l=1}^m \\alpha_{li} x_{lj},\\quad,i=1,2,\\cdots,m,\\quad j=1,2,\\cdots,n$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=4>**数据矩阵的奇异值分解算法**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定样本矩阵 $X$，假设有 $k$ 个主成分，对于 $m\\times n$ 实矩阵 $A$，假设其秩为 $r, 0<k<r$，则可以将矩阵 $A$ 进行截断奇异值分解 <font size=4> $A \\approx U_k\\Sigma_k V_k^T$ </font> ；式中，$U_k$ 是 $m\\times k$ 矩阵, $V_k$ 是 $n\\times k$ 矩阵， $\\Sigma_k$ 是 $k$ 阶对角矩阵； $U_k,V_k$ 分别由取 $A$ 的完全奇异值分解的矩阵 $U,V$ 的前 $k$ 列， $\\Sigma_k$ 由取 $A$ 的完全奇异分解的矩阵 $\\Sigma$ 的前 $k$ 个对角线元素得到。\n",
    "\n",
    "定义一个新的 $n\\times m$ 矩阵 $X^{'}$\n",
    "#### $$X^{'} = \\frac{1}{\\sqrt{n-1}} X^T$$\n",
    "$X^{'}$ 的每一列均值为零，因此：\n",
    "#### $$X^{'T}X^{'} = \\Big(\\frac{1}{\\sqrt{n-1}} X^T\\Big)^T \\Big(\\frac{1}{\\sqrt{n-1}} X^T\\Big) = \\frac{1}{n=1}XX^T$$\n",
    "即 $X^{'T}X^{'}$ 等于 $X$ 的协方差矩阵 $S_X$： $S_X = X^{'T}X^{'}$ \n",
    "\n",
    "**主成分分析归结于求协方差矩阵 $S_X$ 的特征值和对应的单位特征向量，所以问题转化为求矩阵 $X^{'T}X^{'}$ 的特征值和对应的单位特征向量**\n",
    "\n",
    "假设 $X^{'}$ 的截断奇异值分解为 $X^{'} = U\\sigma V^T$，那么 $V$ 的列向量就是 $S_X = X^{'T}X^{'}$ 的单位特征向量。因此，$V$ 的列向量就是$X$的主成分。于是 ，求 $X$ 主成分可以通过求 $X^{'}$ 的奇异值分解来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$ <font size=4> **主成分分析算法** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：$m\\times n$ 样本矩阵 $X$，其每一行元素的均值为零\n",
    "\n",
    "输出：$k\\times n$ 样本主成分矩阵 $Y$ \n",
    "\n",
    "参数：主成分个数 $k$ \n",
    "\n",
    "（1）构造新的 $n\\times m$ 矩阵 <font size=4> $X^{'} = \\frac{1}{\\sqrt{n-1}} X^T$ </font> ，$X^{'}$ 每一列的均值为零。\n",
    "\n",
    "（2）对矩阵 $X^{'}$ 进行截断奇异值分解，得到 <font size=4> $X^{'} = U\\Sigma V^T$ </font> ，有 $k$ 个奇异值、奇异向量。矩阵 $V$ 的前 $k$ 列构成 $k$ 个样本主成分。\n",
    "\n",
    "（3）求 $k\\times n$ 样本主成分矩阵 <font size=4> $Y = V^T X $</font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=\"red\"> **待做：主成分分析（python 实现）** </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
