{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font><b>第十四章 聚类方法 </b></font> P275 - P290…… 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、聚类是针对给定的样本，依据它们特征的相似度或距离，将其归并到若干个“类” 或 “簇” 的数据分析问题。一个类是样本的一个子集。\n",
    "\n",
    "2、聚类的目的是通过得到的类或簇来发现数据的特点或对数据进行处理，在数据挖掘、模式识别等领域有着广泛的应用。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **一、聚类的基本概率**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**聚类的核心概念是相似度（similarity）或距离（distance)。相似度直接影响聚类的结果，所以其选择是聚类的根本问题。**\n",
    "\n",
    "\n",
    "聚类的对象是观测数据，或样本集合。假设有 $n$ 个样本，每个样本由 $m$ 个属性的特征向量组成。样本集合可以用矩阵 $X$ 表示：\n",
    "#### $$X = [x_{ij}]_{m\\times n} = \\left[\\begin{align}& x_{11} \\quad & x_{12}\\quad & \\cdots & x_{1n}\\\\\n",
    "                                                   & x_{21} \\quad & x_{22}\\quad & \\cdots & x_{2n} \\\\\n",
    "                                                   & \\vdots \\quad & \\vdots\\quad & \\quad  & \\vdots \\\\ \n",
    "                                                   & x_{m1} \\quad & x_{m2}\\quad & \\cdots & x_{mn}  \\end{align}\\right]$$\n",
    "矩阵 第 $j$ 列表示第 $j$ 个样本， $j=1,2,\\cdots,n$; 第i行表示第 $i$个属性， $i=1,2,\\cdots,m$； 矩阵元素 $x_{ij}$ 表示第 $j$ 个样本的第 $i$ 个属性值；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（闵可夫斯基距离）** 给定样本集合 $X,Y$ 是 $m$ 维实数向量空间 $\\mathcal {R^m}$ 中的点集合，其中 $x_i,x_j\\in X, x_i = (x_{1i},x_{2i},\\cdots,x_{mi})^T, x_j = (x_{1j},x_{2j},\\cdots,x_{mj})^T$ , 样本 $x_i$ 与样本 $x_j$ 的 闵可夫斯基距离定义为\n",
    "### $$ d_{ij} = \\Big( \\sum_{k=1}^m |x_{ki} - x_{kj}|^p\\Big)^{\\frac{1}{p}},\\quad p\\geq 1 \\quad $$ \n",
    "#### $$ \\Rightarrow \\left\\{\\begin{align} &p=1, 曼哈顿距离(Manhattan distance):\\quad&        & d_{ij} = \\sum_{k=1}^m |x_{ki} - x_{kj}|  \\\\ \n",
    "                                    &p=2, 欧氏距离 (Euclidean distance):\\quad&              & d_{ij} = \\Big( \\sum_{k=1}^m |x_{ki} - x_{kj}|^2\\Big)^{\\frac{1}{2}} \\\\  \n",
    "                                    &p=\\infty,切比雪夫距离（Chebyshev distance）\\quad &      & d_{ij} = \\max_k |x_{ki} - x_{kj}|,\\quad 取各坐标数值差的绝对值的最大值\\end{align}\\right.$$\n",
    "**闵可夫斯基距离越大相似度越小，距离越小相似度越大**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（马哈拉诺比斯距离，简称马氏距离）**  马氏距离考虑各分量（特征）之间的相关性并与各个分量的尺度无关。\n",
    "\n",
    "给定一个样本集合 $X, X = (x_{ij})_{m\\times n}$, 其协方差矩阵记作 $S$。 样本 $x_i$ 与样本 $x_j$ 之间的马哈拉诺比距离 $d_{ij}$ 记作  \n",
    "#### $$ d_{ij} = \\big[(x_i - x_j)^T S^{-1} (x_i - x_j)\\big]^{\\frac{1}{2}}$$\n",
    "其中，<font size=4> $x_i = (x_{1i}, x_{2i},\\cdots, x_{mi})^T,\\quad x_j = (x_{1j}, x_{2j},\\cdots, x_{mj})^T$ </font>\n",
    "\n",
    "当 $S$ 为单位矩阵时，即样本数据的各个分量相互独立且各个分量的方差为1时，马氏距离即欧氏距离。\n",
    "\n",
    "\n",
    "**马哈拉诺比斯距离（马氏距离）距离越大相似度越小，距离越小相似度越大**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（相关系数(correlation coeffcient)）** 样本之间的相似度也可以用相关系数来表示。 \n",
    "\n",
    "样本 $ x_i, x_j$ 之间的相关系数定义为 \n",
    "### $$ r_{ij} = \\frac{\\sum\\limits_{k=1}^m (x_{ki} - \\bar{x}_i)(x_{kj} - \\bar{x}_j)}{\\Big[ \\sum\\limits_{k=1}^m (x_{ki} - \\bar{x}_i)^2 \\sum\\limits_{k=1}^m (x_{kj} - \\bar{x}_j)^2\\Big]^{\\frac{1}{2}}}$$  \n",
    "其中，<font size=4> $ \\bar{x}_i = \\frac{1}{m} \\sum\\limits_{k=1}^m x_{ki}$ </font> 为第 $ i$ 个样本的均值, <font size=4>  $ \\bar{x}_j = \\frac{1}{m} \\sum\\limits_{k=1}^m x_{kj}$ </font>  为第 $ j$ 个样本的均值\n",
    "\n",
    "**相关系数绝对值越接近于1，表示样本越相似；越接近于0，表示样本越不相似**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（夹角余弦）** 样本之间的相似度也可以用夹角余弦（cosine)来表示。\n",
    "\n",
    "样本 $ x_i, x_j$ 之间的夹角余弦定义为\n",
    "### $$s_{ij} = \\frac{\\sum\\limits_{k=1}^m x_{ki}x_{kj}}{\\Big[ \\sum\\limits_{k=1}^m x_{ki}^2 \\sum\\limits_{k=1}^m x_{kj}^2 \\Big]^\\frac{1}{2}}$$ \n",
    "**夹角余弦越接近于1时，样本越相似；越接近于0时，样本越不相似。**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 如果一个聚类方法假定一个样本只能属于一个类，或类的交集为空集，那么该方法称为**硬聚类（hard clustering) 方法**\n",
    "\n",
    "* 如果一个样本可以属于多个类，或类的交集不为空集，那么该方法称为**软聚类（soft clistering）方法**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义（类或簇）** 设 $T$ 为给定的正数，若集合 $G$ 中任意两个样本 $x_i,x_j$ 有 $d_{ij}\\leq T$， 则称 $G$ 为一个类或簇\n",
    "\n",
    "**定义（类或簇）** 设 $T$ 为给定的正数，若对集合 $G$ 中任意一个样本 $x_i$, 一定存在 $G$ 中的另一个样本 $x_j$ ，使得 $d_{ij}\\leq T$， 则称 $G$ 为一个类或簇\n",
    "\n",
    "**定义（类或簇）** 设 $T$ 为给定的正数，若对集合 $G$ 中任意一个样本 $x_i$, $G$ 中的另一个样本 $x_j$ 满足 <font size=4> $\\frac{1}{n_G -1}\\sum\\limits_{x_j\\in G} d_{ij} \\leq T$ </font>， 其中$n_G$ 为 $G$ 中的样本的个数，则称 $G$ 为一个类或簇 $$  \n",
    "\n",
    "**定义（类或簇）** 设 $T,V$ 为给定的正数，如果集合 $G$ 中任意两个样本 $x_i,x_j$ 的距离 $d_{iij}$ 满足 \n",
    "<font size=4> $\\frac{1}{n_G(n_G -1)}\\sum\\limits_{x_i\\in G}\\sum\\limits_{x_j\\in G} d_{ij} \\leq T \\quad$ </font>，\n",
    "<font size=4> $d_{ij}\\leq V$ </font>， 则称 $G$ 为一个类或簇\n",
    "\n",
    "**类的均值 <font size=4>$\\bar{x}_G$</font>** ,又称类的中心 <font size=5>$\\bar{x}_G = \\frac{1}{n_G} \\sum\\limits_{i=1}^{n_G} x_i$</font>，其中$n_G$ 为 $G$ 中的样本的个数\n",
    "\n",
    "**类的直径（diameter） <font size=4>$D_G$</font>** ： 类的直径 $D_G$ 是类中任意两个样本之间的最大距离，即<font size=4> $D_G = \\max\\limits_{x_i,x_j\\in G} d_{ij}$</font>\n",
    "\n",
    "**类的样本散布矩阵（scatter matrix）A_G**：<font size=4> $A_G = \\sum\\limits_{i=1}^{n_G}(x_i - \\bar{x}_G)(x_i - \\bar{x}_G)^T$ </font>\n",
    "\n",
    "**样本协方差矩阵S_G** : <font size=4> $ S_G = \\frac{1}{m-1}A_G = \\frac{1}{m-1} \\sum\\limits_{i=1}^{n_G}(x_i - \\bar{x}_G)(x_i - \\bar{x}_G)^T$ </font>， 其中，m为样本的维数（样本的属性个数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **类与类之间的距离**\n",
    "\n",
    "设类$G_p$ 包含 $n_p$ 个样本，类 $G_q$ 包含 $n_q$ 个样本，$\\bar{x}_p, \\bar{x}_q$ 分别为 $G_p,G_q$的均值，即类的中心，**定义类 $G_p,G_q$ 之间的距离 $D(p,q) $** \n",
    "\n",
    "(1) **最短距离或单连接（single linkage）** : <font size=4> $D_{pq} = min \\{d_{ij} | x_i \\in G_p,x_j \\in G_q\\}$ </font>\n",
    "\n",
    "(2)  **最长距离或单连接（complete linkage）** : <font size=4> $D_{pq} = max \\{d_{ij} | x_i \\in G_p,x_j \\in G_q\\}$ </font>\n",
    "\n",
    "(3)  **中心距离** : <font size=5> $D_{pq} = d_{\\bar{x}_p \\bar{x}_q}$ </font>\n",
    "\n",
    "(4)  **平均距离** : <font size=5> $D_{pq} = \\frac{1}{n_p n_q} \\sum\\limits_{x_i \\in G_p} \\sum\\limits_{x_j \\in G_q} d_{ij}$ </font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **二、层次聚类** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 层次聚类假设类别之间存在层次结构，将样本聚到层次化的类中。\n",
    "\n",
    "* 层次聚类属于硬聚类，每一个样本只属于一个类。\n",
    "\n",
    "* 层次聚类有聚合(agglomerative) 或 自下而上（bottom-up）聚类、分裂（divisive）或自上而下（top-down）聚类两种方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（聚合聚类算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：$n$ 个样本组成的样本集合及样本之间的距离\n",
    "\n",
    "输出：对样本集合的一个层次化聚类\n",
    "\n",
    "（1）计算 $n$ 个样本两两之间的欧氏距离 $\\{d_{ij}\\}$, 记作矩阵 $D = [d_{ij}]_{n\\times n}$\n",
    "\n",
    "（2）构造 $n$ 个类，每个类只包含一个样本\n",
    "\n",
    "（3）合并类间最小的两个类，其中最短距离为类间距离，构建一个新类。\n",
    "\n",
    "（4）计算新类与当前各类的距离，若类的个数为 1，终止计算，否则 返回（3） "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **三、k均值聚类** P283 - P287 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* k均值聚类将样本划分为 $k$ 个子集，构成 $k$ 个类，将 $n$ 个样本分到 $k$ 个类中，**每个样本到其所属类的中心的距离最小。**\n",
    "\n",
    "* $k$均值聚类是硬聚类。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\quad$<font size=3><b>   算法（聚合聚类算法）</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：$n$ 个样本的集合 $X$\n",
    "\n",
    "输出：样本集合聚类 $C$\n",
    "\n",
    "（1）初始化。令 $t = 0$, 随机选择 $k$ 个样本点作为初始聚类中心 $m^{(0)} = (m_1^{(0)},\\cdots,m_l^{(0)},\\cdots,m_k^{(0)})$ \n",
    "\n",
    "（2）对样本进行聚类。对固定的类中心 $m^{(t)} =  (m_1^{(t)},\\cdots,m_l^{(t)},\\cdots,m_k^{(t)})$ ，其中 $m_l^{(t)}$ 为类 $G_l$ 的中心，计算每个样本到类中心的距离，将每个样本指派到与其最近的中心的类中，构成聚类结果 $C^{(t)}$\n",
    "\n",
    "（3）计算新的类中心。对聚类结果 $C^{(t)}$， 计算当前各个类中的样本的均值，作为新的类中心 $m^{(t+1)} =  (m_1^{(t+1)},\\cdots,m_l^{(t+1)},\\cdots,m_k^{(t+1)})$ \n",
    "\n",
    "（4）如果迭代收敛或符合停止条件，输出 $C^* = C^{(t)}$, 否则令 $t = t+1$，返回（2）\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"exp14.2.png\" height=200 width = 400></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "def cal_eulidean(x1,x2): # 计算欧氏距离\n",
    "    return np.sqrt(np.sum( np.power(x1-x2,2) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check1: n: 0 continue_cnt: 1 X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]] 0\n",
      "check1: n: 1 continue_cnt: 2 X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]] 1\n",
      "check1: n: 2 continue_cnt: 3 X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]] 1\n",
      "check1: n: 3 continue_cnt: 4 X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]] 1\n",
      "check1: n: 4 continue_cnt: 5 X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]] 0\n",
      "新的类中心点： [[2.5 2. ]\n",
      " [2.  0. ]]\n",
      "本次循环 continue_cnt: 5 continue_Flag: True X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]]\n",
      "新的类中心点： [[2.5 2. ]\n",
      " [2.  0. ]]\n",
      "xG: [[0, 2, 0], [0, 0, 1], [1, 0, 1], [5, 0, 1], [5, 2, 0]] G: {0: [[0, 2], [5, 2]], 1: [[0, 0], [1, 0], [5, 0]]}\n",
      "本次循环 continue_cnt: 0 continue_Flag: False X: [[0 0 1 5 5]\n",
      " [2 0 0 0 2]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1,5,5],[2,0,0,0,2]])\n",
    "\n",
    "_K = 2 # k个聚类\n",
    "_G = {} # 存储聚类结果: {0:[第0类的样本点],1:[第1类的样本点],...,k-1:[第k-1类的样本点]}\n",
    "_xG = []  # 存储每个点对应的类别  例：[[0，2，0],[0，0，1]。。。] 最后一个值对应类别\n",
    "\n",
    "_N = X.shape[1] # 样本点个数\n",
    "\n",
    "# 初始化类中心  \n",
    "_C = np.array(X[:,0:_K],dtype = np.float32) # 存储聚类中心点\n",
    "\n",
    "# 初始化聚类结果集  _G = {0: [], 1: []}\n",
    "for k in range(_K):\n",
    "    if k not in _G.keys():\n",
    "        _G[k] = []\n",
    "\n",
    "\n",
    "continue_Flag = True # 是否结束循环标志 若没有样本点需要再改变类别，则该值置为False 循环结束\n",
    "\n",
    "while continue_Flag:\n",
    "    \n",
    "    continue_Flag_cnt = 0 # 计数器，计算该循环中，有多少点归到新的类中\n",
    "    \n",
    "    # step2: 统计每个样本点距离类中心的距离，距离最近的类为该样本点所在类    \n",
    "    # dist = [] # 计算每个样本点与 类中心的距离 N行，K列\n",
    "    \n",
    "    for n in range(_N): \n",
    "        x = X[:,n]\n",
    "        temp_dist = [cal_eulidean(x,_C[:,k]) for k in range(_K)] # 计算样本点x 与 类中心_C中，每个类心的距离        \n",
    "        min_dist_index = temp_dist.index(np.min(temp_dist)) # 找出距离最短的类别\n",
    "        \n",
    "        ## 更新 聚类结果 _G,_xG\n",
    "        if len(_xG)<_N: ## 全部的样本点还没有全存入xG中(取第一次聚类)\n",
    "            temp = list(x)\n",
    "            temp.append(min_dist_index)\n",
    "            \n",
    "            _xG.append(temp) # 直接更新样本结果集 xG\n",
    "            _G[min_dist_index].append(list(x)) # 直接更新聚类结果集\n",
    "            \n",
    "            continue_Flag_cnt += 1 # 计数器加1    \n",
    "            \n",
    "            print(\"check1:\",\"n:\",n,\"continue_cnt:\",continue_Flag_cnt,\"X:\",X,_xG[n][2] )\n",
    "            \n",
    "        elif _xG[n][2] != min_dist_index :  # 如果当前聚类的结果跟之前的不一样，更新数据\n",
    "            \n",
    "            last_cluster = _xG[n][2]\n",
    "            \n",
    "            # _G 中，把样本点x从原始分类中去掉，再归到新的分类中 \n",
    "            _G[last_cluster].remove(list(x))       \n",
    "            _G[min_dist_index].append(list(x))\n",
    "            \n",
    "            # _xG中，直接更新样本n的对应类别\n",
    "            _xG[n][2] = min_dist_index\n",
    "            \n",
    "            continue_Flag_cnt += 1 \n",
    "            \n",
    "            print(\"check2:\",\"n:\",n,\"continue_cnt:\",continue_Flag_cnt)\n",
    "\n",
    "    ## step3: 重新计算类中心 _C\n",
    "    for k in range(_K):\n",
    "        _C[:,k] = np.cumsum(_G[k],0)[-1] / len(_G[k])\n",
    "    \n",
    "    print(\"新的类中心点：\",_C)\n",
    "            \n",
    "    # step4: 判断是否结束循环 结束循环条件：没有样本点需要再移动 \n",
    "    if continue_Flag_cnt == 0:        \n",
    "        print(\"xG:\",_xG,\"G:\",_G)\n",
    "        continue_Flag = False \n",
    "        \n",
    "    print(\"本次循环\",\"continue_cnt:\",continue_Flag_cnt,\"continue_Flag:\",continue_Flag,\"X:\",X)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1812fddacc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 画图 \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "for key in _G.keys():\n",
    "    val = _G[key]\n",
    "    \n",
    "    x = [v[0] for v in val]\n",
    "    y = [v[1] for v in  val]\n",
    "    plt.scatter(x,y,label = key)\n",
    "    \n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **K均值聚类的特点：**\n",
    "\n",
    "（1）**总体特点** k均值聚类是基于划分的聚类方法：类别数 k 事先指定；以欧氏距离平方表示样本之间的距离，以中心或样本均值表示类别；\n",
    "\n",
    "（2）**收敛性** k均值聚类属于启发式方法，不能保证收敛到全局最优，**初始中心的选择会直接影响聚类的结果**\n",
    "\n",
    "（3）**初始类的选择** 选择不同的初始类，会得到不同的聚类结果。初始中心的选择，可以用层次聚类对样本进行聚类，得到 k 个类时停止。然后从每个类中选取一个与中心距离最近的点。\n",
    "\n",
    "（4）**类别数 k 的选择** k均值聚类中类别数k值需要预先指定，而在实际应用中最优的k值是不知道的。解决这一问题的一个方法是尝试不同的k值聚类，检验各自得到聚类结果的质量，推测最优k值。**聚类结果的质量可以用类的平均直径来衡量。** 一般，类别数变小时，平均直径会增加；类别变大或超过某个值后，平均直径会不变；而这个值，正是最优的k值。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
